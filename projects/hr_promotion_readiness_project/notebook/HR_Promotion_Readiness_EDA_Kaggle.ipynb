{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2773e9fd",
   "metadata": {},
   "source": [
    "# HR Promotion Readiness Analysis (EDA + Cleaning + ML Prep)\n",
    "\n",
    "This notebook follows an end-to-end EDA workflow:\n",
    "\n",
    "1. Data audit & cleaning  \n",
    "2. Univariate analysis  \n",
    "3. Bivariate analysis vs **is_promoted**  \n",
    "4. Multivariate analysis  \n",
    "5. Business insights & “overlooked talent” identification  \n",
    "6. Optional: ML-ready dataset export\n",
    "\n",
    "> Tip (Kaggle): If you added the CSV as a Kaggle Dataset, update `KAGGLE_INPUT_PATH` below (or just use the auto-detect logic).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d01e126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Viz\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "pd.set_option(\"display.max_columns\", 200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e63e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1) Load data (Kaggle-friendly) ---\n",
    "\n",
    "# If you're on Kaggle, your dataset will look like:\n",
    "# /kaggle/input/<your-dataset-name>/HR_Analytics_Dataset.csv\n",
    "KAGGLE_INPUT_PATH = \"/kaggle/input/hr-analytics-dataset/HR_Analytics_Dataset.csv\"  # <-- change if needed\n",
    "\n",
    "# Fallbacks (works locally / other environments)\n",
    "FALLBACK_PATHS = [\n",
    "    KAGGLE_INPUT_PATH,\n",
    "    \"/kaggle/input/HR_Analytics_Dataset.csv\",\n",
    "    \"../input/hr-analytics-dataset/HR_Analytics_Dataset.csv\",\n",
    "    \"HR_Analytics_Dataset.csv\",\n",
    "]\n",
    "\n",
    "DATA_PATH = next((p for p in FALLBACK_PATHS if os.path.exists(p)), None)\n",
    "if DATA_PATH is None:\n",
    "    raise FileNotFoundError(\n",
    "        \"Could not find HR_Analytics_Dataset.csv. \"\n",
    "        \"Update KAGGLE_INPUT_PATH or upload the file to the notebook environment.\"\n",
    "    )\n",
    "\n",
    "df_raw = pd.read_csv(DATA_PATH)\n",
    "print(\"Loaded:\", DATA_PATH)\n",
    "df_raw.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c0748e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic structure\n",
    "print(\"Shape:\", df_raw.shape)\n",
    "display(df_raw.info())\n",
    "display(df_raw.describe(include=\"all\").T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70889a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique values audit (quick scan)\n",
    "for col in df_raw.columns:\n",
    "    nunq = df_raw[col].nunique(dropna=False)\n",
    "    print(f\"{col:22s}  unique={nunq:4d}  missing={df_raw[col].isna().sum():5d}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3aab15",
   "metadata": {},
   "source": [
    "## 2) Cleaning & preparation\n",
    "\n",
    "We will:\n",
    "- Remove fully duplicated rows (including duplicated employee records)\n",
    "- Standardize and fix known categorical typos/inconsistencies\n",
    "- Handle missing values (simple, explainable imputations)\n",
    "- Ensure correct data types\n",
    "- Create a cleaned dataframe: `df`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b870fbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_raw.copy()\n",
    "\n",
    "# 2.1 Drop exact duplicate rows (dataset has some)\n",
    "before = len(df)\n",
    "df = df.drop_duplicates()\n",
    "print(\"Dropped duplicates:\", before - len(df))\n",
    "\n",
    "# 2.2 Standardize strings\n",
    "def clean_str(x):\n",
    "    if pd.isna(x): \n",
    "        return np.nan\n",
    "    return str(x).strip()\n",
    "\n",
    "for c in [\"department\", \"region\", \"education\", \"gender\", \"recruitment_channel\"]:\n",
    "    if c in df.columns:\n",
    "        df[c] = df[c].map(clean_str)\n",
    "\n",
    "# 2.3 Fix common typos / label inconsistencies\n",
    "dept_map = {\n",
    "    \"Sales & Markting\": \"Sales & Marketing\",\n",
    "    \"Opperations\": \"Operations\",\n",
    "    \"Technoogy\": \"Technology\",\n",
    "}\n",
    "df[\"department\"] = df[\"department\"].replace(dept_map)\n",
    "\n",
    "# Gender normalization (dataset uses 'm'/'f')\n",
    "gender_map = {\"m\": \"Male\", \"f\": \"Female\", \"M\": \"Male\", \"F\": \"Female\"}\n",
    "df[\"gender\"] = df[\"gender\"].replace(gender_map)\n",
    "\n",
    "# Region normalization (ensure consistent casing)\n",
    "df[\"region\"] = df[\"region\"].str.lower()\n",
    "\n",
    "# Education normalization\n",
    "edu_map = {\n",
    "    \"Master's & above\": \"Masters & above\",\n",
    "    \"Master’s & above\": \"Masters & above\",  # curly apostrophe, if present\n",
    "}\n",
    "df[\"education\"] = df[\"education\"].replace(edu_map)\n",
    "\n",
    "# 2.4 Missing value handling\n",
    "# Categorical: fill with 'Unknown' (keeps rows, preserves signal that it was missing)\n",
    "for c in [\"department\", \"region\", \"education\", \"gender\"]:\n",
    "    df[c] = df[c].fillna(\"Unknown\")\n",
    "\n",
    "# previous_year_rating: impute median by department, fallback to global median\n",
    "if \"previous_year_rating\" in df.columns:\n",
    "    global_median = df[\"previous_year_rating\"].median()\n",
    "    df[\"previous_year_rating\"] = df.groupby(\"department\")[\"previous_year_rating\"].transform(\n",
    "        lambda s: s.fillna(s.median())\n",
    "    )\n",
    "    df[\"previous_year_rating\"] = df[\"previous_year_rating\"].fillna(global_median)\n",
    "\n",
    "# 2.5 Types\n",
    "int_cols = [\"employee_id\", \"no_of_trainings\", \"age\", \"length_of_service\", \"KPIs_met >80%\", \"awards_won?\", \"is_promoted\"]\n",
    "for c in int_cols:\n",
    "    if c in df.columns:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "df[\"avg_training_score\"] = pd.to_numeric(df[\"avg_training_score\"], errors=\"coerce\")\n",
    "\n",
    "# Final sanity check\n",
    "display(df.head())\n",
    "print(\"Cleaned shape:\", df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd66de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check remaining missingness\n",
    "df.isna().sum().sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7866bd83",
   "metadata": {},
   "source": [
    "# 3) Univariate analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21438057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper plotting functions\n",
    "def plot_hist(col, bins=30):\n",
    "    plt.figure(figsize=(7,4))\n",
    "    sns.histplot(df[col].dropna(), bins=bins, kde=True)\n",
    "    plt.title(f\"Distribution: {col}\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_count(col, top_n=None):\n",
    "    plt.figure(figsize=(8,4))\n",
    "    vc = df[col].value_counts()\n",
    "    if top_n:\n",
    "        vc = vc.head(top_n)\n",
    "    sns.barplot(x=vc.index, y=vc.values)\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.title(f\"Count: {col}\")\n",
    "    plt.ylabel(\"count\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_box(col):\n",
    "    plt.figure(figsize=(6,4))\n",
    "    sns.boxplot(y=df[col])\n",
    "    plt.title(f\"Boxplot: {col}\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae979aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical\n",
    "for col in [\"age\", \"avg_training_score\", \"length_of_service\", \"no_of_trainings\"]:\n",
    "    plot_hist(col)\n",
    "    plot_box(col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bf8f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical (top categories)\n",
    "for col in [\"gender\", \"education\", \"department\", \"region\", \"recruitment_channel\"]:\n",
    "    plot_count(col, top_n=20 if col==\"region\" else None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a156a4db",
   "metadata": {},
   "source": [
    "# 4) Bivariate analysis vs promotion (is_promoted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588c2b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Promotion rate overall\n",
    "promo_rate = df[\"is_promoted\"].mean()\n",
    "print(f\"Overall promotion rate: {promo_rate:.3%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86699453",
   "metadata": {},
   "outputs": [],
   "source": [
    "def promo_rate_by(col, top_n=None):\n",
    "    tmp = df.groupby(col)[\"is_promoted\"].mean().sort_values(ascending=False)\n",
    "    if top_n:\n",
    "        tmp = tmp.head(top_n)\n",
    "    plt.figure(figsize=(9,4))\n",
    "    sns.barplot(x=tmp.index, y=tmp.values)\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.title(f\"Promotion rate by {col}\")\n",
    "    plt.ylabel(\"promotion rate\")\n",
    "    plt.ylim(0, max(0.15, tmp.max()*1.2))\n",
    "    plt.show()\n",
    "    return tmp\n",
    "\n",
    "rates_gender = promo_rate_by(\"gender\")\n",
    "rates_dept   = promo_rate_by(\"department\")\n",
    "rates_edu    = promo_rate_by(\"education\")\n",
    "rates_region = promo_rate_by(\"region\", top_n=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9986dde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical vs promotion (boxplots)\n",
    "for col in [\"age\", \"avg_training_score\", \"length_of_service\", \"previous_year_rating\", \"no_of_trainings\"]:\n",
    "    plt.figure(figsize=(7,4))\n",
    "    sns.boxplot(x=\"is_promoted\", y=col, data=df)\n",
    "    plt.title(f\"{col} vs is_promoted\")\n",
    "    plt.xlabel(\"is_promoted\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44164ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KPI and awards impact (grouped bars)\n",
    "for col in [\"KPIs_met >80%\", \"awards_won?\"]:\n",
    "    tmp = df.groupby(col)[\"is_promoted\"].mean().reset_index()\n",
    "    plt.figure(figsize=(5,4))\n",
    "    sns.barplot(x=col, y=\"is_promoted\", data=tmp)\n",
    "    plt.title(f\"Promotion rate by {col}\")\n",
    "    plt.ylim(0, max(0.15, tmp[\"is_promoted\"].max()*1.2))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16e8fed",
   "metadata": {},
   "source": [
    "# 5) Multivariate analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0ad0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap for numerical columns\n",
    "num_cols = [\"age\",\"no_of_trainings\",\"previous_year_rating\",\"length_of_service\",\"KPIs_met >80%\",\"awards_won?\",\"avg_training_score\",\"is_promoted\"]\n",
    "corr = df[num_cols].astype(float).corr()\n",
    "\n",
    "plt.figure(figsize=(9,6))\n",
    "sns.heatmap(corr, annot=True, fmt=\".2f\", cmap=\"vlag\", center=0)\n",
    "plt.title(\"Correlation heatmap (numerical features)\")\n",
    "plt.show()\n",
    "\n",
    "corr[\"is_promoted\"].sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2a733c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairplot (can be slow on full dataset; sample for speed)\n",
    "sample = df.sample(n=min(3000, len(df)), random_state=42)\n",
    "sns.pairplot(sample[[\"age\",\"avg_training_score\",\"length_of_service\",\"previous_year_rating\",\"is_promoted\"]], hue=\"is_promoted\", diag_kind=\"hist\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406ac14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interaction example: rating + training score buckets\n",
    "df[\"training_bucket\"] = pd.cut(df[\"avg_training_score\"], bins=[0,60,70,80,90,100], include_lowest=True)\n",
    "df[\"rating_bucket\"] = df[\"previous_year_rating\"].astype(int)\n",
    "\n",
    "# Convert training_bucket to string to avoid dtype issues\n",
    "df[\"training_bucket\"] = df[\"training_bucket\"].astype(str)\n",
    "\n",
    "pivot = df.pivot_table(\n",
    "    index=\"rating_bucket\",\n",
    "    columns=\"training_bucket\",\n",
    "    values=\"is_promoted\",\n",
    "    aggfunc=\"mean\",\n",
    "    observed=True  # Fix FutureWarning for categorical columns\n",
    ")\n",
    "\n",
    "# Ensure pivot table values are numeric (convert to float)\n",
    "pivot = pivot.astype(float)\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.heatmap(pivot, annot=True, fmt=\".2f\", cmap=\"Blues\")\n",
    "plt.title(\"Promotion rate by Previous Rating x Training Score bucket\")\n",
    "plt.xlabel(\"Training score bucket\")\n",
    "plt.ylabel(\"Previous year rating\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186e9ffe",
   "metadata": {},
   "source": [
    "# 6) Talent identification: high-potential but not promoted\n",
    "\n",
    "A simple, explainable rule (you can tweak thresholds):\n",
    "- **previous_year_rating >= 4**\n",
    "- **avg_training_score >= 80**\n",
    "- **KPIs_met >80% == 1**\n",
    "- Not promoted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a261736f",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_potential = df[\n",
    "    (df[\"previous_year_rating\"] >= 4) &\n",
    "    (df[\"avg_training_score\"] >= 80) &\n",
    "    (df[\"KPIs_met >80%\"] == 1) &\n",
    "    (df[\"is_promoted\"] == 0)\n",
    "].copy()\n",
    "\n",
    "print(\"High potential but not promoted:\", len(high_potential))\n",
    "display(high_potential.head(10))\n",
    "\n",
    "# Where are they concentrated?\n",
    "display(high_potential[\"department\"].value_counts().head(10))\n",
    "display(high_potential[\"region\"].value_counts().head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a472a74",
   "metadata": {},
   "source": [
    "# 7) Fairness & bias checks (EDA-level)\n",
    "\n",
    "We'll compute promotion rates across:\n",
    "- Gender\n",
    "- Education\n",
    "- Region\n",
    "\n",
    "Then flag under-promoted groups vs overall baseline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36505ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = df[\"is_promoted\"].mean()\n",
    "\n",
    "def underpromoted(col, min_n=200):\n",
    "    grp = df.groupby(col).agg(\n",
    "        n=(\"is_promoted\",\"size\"),\n",
    "        promo_rate=(\"is_promoted\",\"mean\")\n",
    "    ).reset_index()\n",
    "    grp[\"delta_vs_overall\"] = grp[\"promo_rate\"] - baseline\n",
    "    # Filter small groups\n",
    "    grp = grp[grp[\"n\"] >= min_n].sort_values(\"promo_rate\")\n",
    "    return grp\n",
    "\n",
    "under_region = underpromoted(\"region\", min_n=300)\n",
    "under_gender = underpromoted(\"gender\", min_n=300)\n",
    "under_edu    = underpromoted(\"education\", min_n=300)\n",
    "\n",
    "display(under_gender)\n",
    "display(under_edu)\n",
    "display(under_region.head(15))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97321f9",
   "metadata": {},
   "source": [
    "# 8) Business insights (fill this in after reviewing plots)\n",
    "\n",
    "Use the cell below to write your final 1–2 page summary in Markdown.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38048995",
   "metadata": {},
   "source": [
    "## Insights & recommendations (draft)\n",
    "\n",
    "**Promotion drivers (from EDA):**\n",
    "- **avg_training_score**: Strongest predictor - employees with higher training scores (especially ≥80) show significantly higher promotion rates. The interaction analysis reveals that high training scores combined with good ratings drive promotion likelihood.\n",
    "- **previous_year_rating**: Critical factor - employees with ratings ≥4 have substantially higher promotion rates. The correlation analysis shows positive association with promotion outcomes.\n",
    "- **KPIs_met >80%**: Binary indicator with strong impact - employees meeting KPIs have significantly higher promotion rates compared to those who don't. Awards won also shows positive correlation but to a lesser extent.\n",
    "\n",
    "**Department / region patterns:**\n",
    "- **Department performance**: Analysis of promotion rates by department reveals variation across departments. Some departments (e.g., Technology, Analytics) may show higher promotion rates, while others (e.g., Operations, HR) may be underperforming relative to the overall baseline.\n",
    "- **Region performance**: Regional analysis shows geographic disparities in promotion rates. Certain regions consistently show lower promotion rates compared to the overall baseline, indicating potential structural or process differences across locations.\n",
    "\n",
    "**Fairness & bias observations (EDA-level):**\n",
    "- **Gender gaps**: Comparison of promotion rates by gender reveals any meaningful differences. If gaps exist, they should be investigated for systemic bias in promotion processes.\n",
    "- **Education gaps**: Analysis shows promotion rates vary by education level. Higher education levels (e.g., Masters & above) may show different promotion patterns compared to Bachelor's or Below Secondary.\n",
    "- **Regional disparities**: The underpromoted analysis identifies specific regions with promotion rates significantly below the overall baseline, suggesting potential geographic bias or resource allocation issues.\n",
    "\n",
    "**Overlooked talent:**\n",
    "- We found **{N_HIGH_POTENTIAL}** employees who meet the “high potential” rule but were not promoted.\n",
    "  - Concentrated in: Top departments include those with the highest counts of overlooked talent (check Cell 27 output for specific departments). Top regions show geographic concentration of high-potential employees who were not promoted.\n",
    "\n",
    "**Actionable recommendations:**\n",
    "1. **Operational recommendation**: Implement a quarterly review process for high-potential employees (rating ≥4, training score ≥80, KPIs met) who haven't been promoted. Create a structured development plan and promotion pathway for these individuals, especially in departments/regions with high concentrations of overlooked talent.\n",
    "2. **Policy / fairness recommendation**: Conduct a formal audit of promotion processes in underperforming regions and departments. Address any systemic biases identified in gender, education, or regional analyses. Establish clear, objective promotion criteria and ensure consistent application across all departments and regions.\n",
    "3. **Talent identification recommendation**: Develop an automated alert system that flags high-potential employees meeting the criteria but not promoted within 12-18 months. Create mentorship programs and targeted development opportunities for these individuals, with special focus on departments showing the highest concentration of overlooked talent.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55019a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto-fill helper for the Markdown cell above\n",
    "N_HIGH_POTENTIAL = len(high_potential)\n",
    "top_depts = high_potential[\"department\"].value_counts().head(3).to_dict()\n",
    "top_regs  = high_potential[\"region\"].value_counts().head(3).to_dict()\n",
    "\n",
    "print(\"N_HIGH_POTENTIAL:\", N_HIGH_POTENTIAL)\n",
    "print(\"Top depts:\", top_depts)\n",
    "print(\"Top regions:\", top_regs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6e1c4b",
   "metadata": {},
   "source": [
    "# 9) Optional: ML-ready dataframe export\n",
    "\n",
    "We will:\n",
    "- One-hot encode categoricals\n",
    "- Keep numerical columns\n",
    "- Save as `hr_ml_ready.csv`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1147f306",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "target = \"is_promoted\"\n",
    "\n",
    "X = df.drop(columns=[target])\n",
    "y = df[target].astype(int)\n",
    "\n",
    "cat_cols = X.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "num_cols = [c for c in X.columns if c not in cat_cols]\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, num_cols),\n",
    "        (\"cat\", categorical_transformer, cat_cols),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "X_proc = preprocess.fit_transform(X)\n",
    "\n",
    "# Build feature names\n",
    "ohe = preprocess.named_transformers_[\"cat\"].named_steps[\"onehot\"]\n",
    "cat_feature_names = ohe.get_feature_names_out(cat_cols)\n",
    "feature_names = np.concatenate([np.array(num_cols), cat_feature_names])\n",
    "\n",
    "X_ml = pd.DataFrame(X_proc.toarray() if hasattr(X_proc, \"toarray\") else X_proc, columns=feature_names)\n",
    "X_ml[target] = y.values\n",
    "\n",
    "X_ml.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3076a5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save ML-ready csv (Kaggle will show it in the Output pane)\n",
    "out_path = \"hr_ml_ready.csv\"\n",
    "X_ml.to_csv(out_path, index=False)\n",
    "print(\"Saved:\", out_path, \"shape:\", X_ml.shape)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
